<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects</title>
    <link href="https://fonts.googleapis.com/css2?family=Kaisei+Decol&display=swap" rel="stylesheet">
    <style>
        /* Insert the updated CSS code here */
    </style>
</head>

<body>
<div class="main-header">
    <div class = "container0">
        <h1>Leadership and Projects</h1>

    </div>
</div>

<div class="navbar">
    <a routerLink="/">Home</a>
    <a routerLink="/experience">Experiences</a>
    <a routerLink="/project">Projects</a>
    <a href="https://github.com/PrakritiPat" target="_blank" class="github-button">
        <button>GitHub</button>
    </a>
</div>

<div class="wrapcontainer1">
    <div class="pcontent-1">
    <div class="pleftcontainer-1">
        <div class="project-1">
            <h1>Leadership: Augmented Reality Game UX Designer Design Lead</h1>
        </div>
        <div class="hcileadership">
        <p>As the Design Lead for an award-winning Augmented Reality (AR) mobile tour app, I directed the end-to-end design, research, and development of an immersive experience that centers the voices of the Native American Thámien Ohlone community. I aided in building by using Unity and Niantic Lightship, and the app has reached over 8,400 views across five interactive storytelling stops, with 15 more in development. I led a design team of 8 researchers, designers, and developers, and collaborated with over eight Ohlone consultants using human-centered design and co-design methods like landmark affinity diagramming. Within an Agile framework, I ran weekly scrum meetings to ensure user feedback was continuously integrated and that our designs remained aligned with both usability goals and technical feasibility. This leadership contributed to our team receiving some of the highest honors in the field, including the CHI 2024 Social Impact Award, the Auggie Award 2024, and Niantic’s 8th Wall Grand Prize for Location-Based AR.
        </p>


          
        </div>
    </div>

    <div class="prightcontainer-1">
        <div class="pinterest">
            <img src="../assets/hciart.png" alt="hciart image">
        </div>
    </div>
</div>
</div>



<div class="wrapcontainer2">
    <div class="pcontent0">
        <div class="pleftcontainer0">
            <div class="project0">
                <h1>Project: Extraction of Data to create Eye-tracking Device</h1>
            </div>
            <div class="vr">
            
            <p>As part of a research initiative focused on immersive technologies, I developed a C# script to extract spatial and behavioral data from Unity-based applications and structured that information into well-organized CSV files for further analysis. I then contributed to building an eye-tracking visualization program that ingested these data points to map user gaze patterns in real time. This system enabled us to accurately analyze where users were looking while wearing VR headsets, providing valuable insights into user attention and interaction. My contributions supported the foundation for usability research and enhanced design decisions for future VR experiences.
                This research focused on understanding how users interact with their VR avatars, particularly whether and how often they look at themselves in virtual mirrors. To support this study, I helped develop an eye-tracking program that captured and visualized user gaze behavior in real time. I wrote a C# script to extract spatial gaze data from Unity-based VR environments and converted it into structured CSV files for analysis. These insights allowed our team to explore the cognitive and behavioral aspects of avatar embodiment and self-recognition in immersive virtual spaces, informing future design and research directions in VR.
            </p>
    
    
              
            </div>
        </div>
    
        <div class="prightcontainer0">
            <div class="spotify">
                <img src="../assets/IVRart.png" alt="csv Image">
            </div>
        </div>
    </div>
    
</div>

<div class="wrapcontainer3">
    <div class="pcontent">
        <div class="pleftcontainer">
            <div class="project1">
                <h1>Project: Development of Weapon Detector Device for Police Officers</h1>
            </div>
            <div class="lassen">
            
            <p>At Lassen Peak, I developed diagnostic and performance benchmarking tools in Python and C++ to evaluate radar-based embedded systems designed for concealed weapon detection. I worked closely with low-level hardware interfaces, testing communication protocols such as I2C and SPI to ensure reliable sensor integration. To reflect the system’s real-world embedded constraints, I wrote custom scripts that monitored RAM and CPU usage under load. I also built dashboards in Tableau and Excel (leveraging advanced formulas and macros) to track signal integrity and performance metrics over time. In addition to performance analysis, I supported quality assurance efforts through bug tracking systems and contributed to real-time debugging of multi-threaded sensor data pipelines. I followed test-driven development practices using NUnit, writing unit tests to validate embedded analytics workflows. My work directly contributed to improving device accuracy and system stability under field conditions.</p>
    
    
              
            </div>
        </div>
    
        <div class="prightcontainer">
            <div class="weatherappimage">
                <img src="../assets/lassenpeakimage.png" alt="lassen">
            </div>
        </div>
    </div>
</div>

